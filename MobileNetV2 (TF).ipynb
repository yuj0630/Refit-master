{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1BFJqM0N2gFQoNAEl_3xGTBCozEYCVc9r","authorship_tag":"ABX9TyNO0QYBTUP30wbaAQaIl0DS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install keras_preprocessing"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vBOs8IzNe7t9","executionInfo":{"status":"ok","timestamp":1686537769218,"user_tz":-540,"elapsed":5707,"user":{"displayName":"정영운","userId":"08661002276326861946"}},"outputId":"34e84a9b-a995-4d67-80f9-2ce622ca2d3c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras_preprocessing\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.22.4)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.16.0)\n","Installing collected packages: keras_preprocessing\n","Successfully installed keras_preprocessing-1.1.2\n"]}]},{"cell_type":"code","source":["!pip install keras_optimizers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vKYivXFSfIsW","executionInfo":{"status":"ok","timestamp":1686537818867,"user_tz":-540,"elapsed":2087,"user":{"displayName":"정영운","userId":"08661002276326861946"}},"outputId":"344af6e5-e8d6-4142-dbd4-cb5b7a34a44e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement keras_optimizers (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for keras_optimizers\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aaZXUYFzW9m4","colab":{"base_uri":"https://localhost:8080/","height":390},"executionInfo":{"status":"error","timestamp":1686537772960,"user_tz":-540,"elapsed":5,"user":{"displayName":"정영운","userId":"08661002276326861946"}},"outputId":"b50211e1-ee8c-4eed-b732-deb77068bd58"},"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-9406858ef035>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madam_v2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'adam_v2' from 'keras.optimizers' (/usr/local/lib/python3.10/dist-packages/keras/optimizers/__init__.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import random\n","import os\n","import time\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","%matplotlib inline\n","import plotly.express as px\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","import tensorflow_hub as hub\n","\n","import keras_preprocessing\n","from keras_preprocessing import image\n","from keras_preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ReduceLROnPlateau\n","\n","from keras import Sequential\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.optimizers import adam_v2\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.layers import Flatten, Dense, BatchNormalization, Activation,Dropout\n","\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras import Model"]},{"cell_type":"code","source":["TRAINING_DIR = '/content/drive/MyDrive/Refit/dataset_3'\n","BATCH_SIZE = 32\n","IMAGE_SIZE = (224, 224)\n","EPOCHS = 100\n","LEARNING_RATE = 0.001"],"metadata":{"id":"LdBfjYGCXLFZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_names = os.listdir(TRAINING_DIR)\n","file_names[:10]"],"metadata":{"id":"P-yY7d3j8qwe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv('/content/drive/MyDrive/Refit/images.csv')"],"metadata":{"id":"y4lro0iDXRDk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data['image'] = data['image']+'.jpg'\n","data_1 = data[['image', 'label']]"],"metadata":{"id":"XnWeAt0HXTdB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import PIL\n","from pathlib import Path\n","from PIL import UnidentifiedImageError\n","\n","path = Path(TRAINING_DIR).rglob(\"*.jpg\")\n","for img_p in path:\n","    try:\n","        img = PIL.Image.open(img_p)\n","    except PIL.UnidentifiedImageError:\n","            print(img_p)"],"metadata":{"id":"pwWiJW-fXVT4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame(columns=['img_path', 'label'])\n","df['img_path'] = all_img_list\n","df['label'] = df['img_path'].apply(lambda x : str(x).split('/')[2])"],"metadata":{"id":"BQ6x9TMDXXRZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train, val, _, _ = train_test_split(df, df['label'], test_size=0.3, stratify=df['label'], random_state=CFG['SEED'])"],"metadata":{"id":"-e6AjENqXZ3p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["le = preprocessing.LabelEncoder()\n","train['label'] = le.fit_transform(train['label'])\n","val['label'] = le.transform(val['label'])"],"metadata":{"id":"WqjZnemtXb9Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Custom Dataset"],"metadata":{"id":"D02-Q1-XXf4z"}},{"cell_type":"code","source":["train_datagen = ImageDataGenerator(rescale=1./255,\n","                                  rotation_range=40,\n","                                  width_shift_range=0.3,\n","                                  height_shift_range=0.3,\n","                                  zoom_range=0.3,\n","                                  horizontal_flip=True,\n","                                  validation_split=0.1)\n","\n","train_generator = train_datagen.flow_from_dataframe(\n","    dataframe=data_1,\n","    directory=TRAINING_DIR,\n","    x_col='image',\n","    y_col='label',\n","    target_size=IMAGE_SIZE,\n","    class_mode='categorical',\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n","    subset='training'\n",")\n","\n","validation_generator = train_datagen.flow_from_dataframe(\n","    dataframe=data_1,\n","    directory=TRAINING_DIR,\n","    x_col='image',\n","    y_col='label',\n","    target_size=IMAGE_SIZE,\n","    class_mode='categorical',\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    subset='validation'\n",")"],"metadata":{"id":"wKQZ5wNMXfPZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n","\n","pre_trained_model = MobileNetV2(input_shape=(224, 224, 3),\n","                                include_top=False,\n","                                weights='imagenet')\n","\n","for layer in pre_trained_model.layers:\n","    layer.trainable = True\n","\n","# pre_trained_model.summary()\n","\n","last_layer = pre_trained_model.get_layer('out_relu')\n","print('last layer output shape: ', last_layer.output_shape)\n","last_output = last_layer.output"],"metadata":{"id":"YXg06SQAXmE5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = Flatten()(last_output)\n","x = Dropout(0.3)(x)\n","x = Dense(256, activation='relu', kernel_regularizer='l2')(x)\n","x = Dropout(0.3)(x)\n","x = Dense(16, activation='softmax')(x)\n","\n","model = Model(pre_trained_model.input, x)"],"metadata":{"id":"8JY_XFcyXo55"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["learn_rate = LEARNING_RATE\n","\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n","cb = ModelCheckpoint('mobilenetv2.h5', save_best_only=True)\n","lrr= ReduceLROnPlateau(monitor='val_accuracy', factor=.1, patience=5, min_lr=1e-5)\n","\n","adam = adam_v2.Adam(learning_rate=learn_rate)\n","model.compile(loss='categorical_crossentropy',optimizer=adam, metrics=['accuracy'])\n","\n","\n","history = model.fit(train_generator, epochs=EPOCHS,\n","                    validation_data=validation_generator,\n","                    callbacks=[es, cb, lrr])\n","\n","model = tf.keras.models.load_model('mobilenetv2.h5')"],"metadata":{"id":"NUJoQQWgXrsI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss, accuracy = model.evaluate(validation_generator, verbose=0)"],"metadata":{"id":"EL0CHyxmXvTg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Model Loss is {loss:.2f} and Accuracy is {100*np.round(accuracy, 4)}%\")"],"metadata":{"id":"EN2xdMWOXzhI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_loss_curves(history):\n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","\n","    accuracy = history.history['accuracy']\n","    val_accuracy = history.history['val_accuracy']\n","\n","    epochs = range(len(history.history['loss']))\n","\n","    # Plot loss\n","    plt.plot(epochs, loss, label='training_loss')\n","    plt.plot(epochs, val_loss, label='val_loss')\n","    plt.title('Loss')\n","    plt.xlabel('Epochs')\n","    plt.legend()\n","\n","    # Plot accuracy\n","    plt.figure()\n","    plt.plot(epochs, accuracy, label='training_accuracy')\n","    plt.plot(epochs, val_accuracy, label='val_accuracy')\n","    plt.title('Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.legend()"],"metadata":{"id":"AHv0etbZX18I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dataset = CustomDataset(test['img_path'].values, None, test_transform)\n","test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"],"metadata":{"id":"ESN1_fevX6Uo"},"execution_count":null,"outputs":[]}]}